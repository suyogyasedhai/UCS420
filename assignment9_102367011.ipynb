{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3ffa60-91cb-4cc6-8456-457afc41ec98",
   "metadata": {},
   "source": [
    "# Q1. Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports, technology, food, books, etc.).\n",
    "1. Convert text to lowercase and remove punctuation.\n",
    "2. Tokenize the text into words and sentences.\n",
    "3. Remove stopwords (using NLTK's stopwords list).\n",
    "4. Display word frequency distribution (excluding stopwords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9b75ace-b2aa-450f-8ea3-f791cb5fa6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b5b545-743e-4c8f-8630-79a621fe5e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\suyog\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\suyog\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\suyog\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\suyog\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edd421a7-0026-47ef-bc33-2b022ac2f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Artificial Intelligence (AI) is reshaping the world in ways we never imagined. From smart assistants like Alexa to autonomous vehicles, AI is becoming part of everyday life. The rise of machine learning algorithms has made it possible to predict outcomes with jaw-dropping accuracy. Companies like OpenAI and DeepMind are pushing the boundaries of what's possible with large language models. If you're curious about AI projects, check out www.futureofai.org for some mind-blowing innovations. Researchers often share insights via email, like at ai.research@futuremail.com, to collaborate and exchange ideas. AI has even entered healthcare, assisting doctors in diagnosing diseases faster and more accurately. However, there are concerns about job automation, data privacy, and ethical implications. If you ever want to attend an AI workshop, call +91 9876543210 — they’re happening worldwide. Despite the challenges, one thing is certain: AI isn’t just the future — it’s already here.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36987942-1482-4378-9e75-a70010b5c425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "artificial intelligence ai is reshaping the world in ways we never imagined from smart assistants like alexa to autonomous vehicles ai is becoming part of everyday life the rise of machine learning algorithms has made it possible to predict outcomes with jawdropping accuracy companies like openai and deepmind are pushing the boundaries of whats possible with large language models if youre curious about ai projects check out wwwfutureofaiorg for some mindblowing innovations researchers often share insights via email like at airesearchfuturemailcom to collaborate and exchange ideas ai has even entered healthcare assisting doctors in diagnosing diseases faster and more accurately however there are concerns about job automation data privacy and ethical implications if you ever want to attend an ai workshop call 91 9876543210 — they’re happening worldwide despite the challenges one thing is certain ai isn’t just the future — it’s already here\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_lower = text.lower()\n",
    "text_clean = text_lower.translate(str.maketrans('', '', string.punctuation))\n",
    "print(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5138be00-e8aa-44b8-9a50-016880e8bf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artificial', 'intelligence', 'ai', 'is', 'reshaping', 'the', 'world', 'in', 'ways', 'we', 'never', 'imagined', 'from', 'smart', 'assistants', 'like', 'alexa', 'to', 'autonomous', 'vehicles', 'ai', 'is', 'becoming', 'part', 'of', 'everyday', 'life', 'the', 'rise', 'of', 'machine', 'learning', 'algorithms', 'has', 'made', 'it', 'possible', 'to', 'predict', 'outcomes', 'with', 'jawdropping', 'accuracy', 'companies', 'like', 'openai', 'and', 'deepmind', 'are', 'pushing', 'the', 'boundaries', 'of', 'whats', 'possible', 'with', 'large', 'language', 'models', 'if', 'youre', 'curious', 'about', 'ai', 'projects', 'check', 'out', 'wwwfutureofaiorg', 'for', 'some', 'mindblowing', 'innovations', 'researchers', 'often', 'share', 'insights', 'via', 'email', 'like', 'at', 'airesearchfuturemailcom', 'to', 'collaborate', 'and', 'exchange', 'ideas', 'ai', 'has', 'even', 'entered', 'healthcare', 'assisting', 'doctors', 'in', 'diagnosing', 'diseases', 'faster', 'and', 'more', 'accurately', 'however', 'there', 'are', 'concerns', 'about', 'job', 'automation', 'data', 'privacy', 'and', 'ethical', 'implications', 'if', 'you', 'ever', 'want', 'to', 'attend', 'an', 'ai', 'workshop', 'call', '91', '9876543210', '—', 'they', '’', 're', 'happening', 'worldwide', 'despite', 'the', 'challenges', 'one', 'thing', 'is', 'certain', 'ai', 'isn', '’', 't', 'just', 'the', 'future', '—', 'it', '’', 's', 'already', 'here']\n",
      "['\\nartificial intelligence ai is reshaping the world in ways we never imagined from smart assistants like alexa to autonomous vehicles ai is becoming part of everyday life the rise of machine learning algorithms has made it possible to predict outcomes with jawdropping accuracy companies like openai and deepmind are pushing the boundaries of whats possible with large language models if youre curious about ai projects check out wwwfutureofaiorg for some mindblowing innovations researchers often share insights via email like at airesearchfuturemailcom to collaborate and exchange ideas ai has even entered healthcare assisting doctors in diagnosing diseases faster and more accurately however there are concerns about job automation data privacy and ethical implications if you ever want to attend an ai workshop call 91 9876543210 — they’re happening worldwide despite the challenges one thing is certain ai isn’t just the future — it’s already here']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = word_tokenize(text_clean)\n",
    "sent_tokens = sent_tokenize(text_clean)\n",
    "print(word_tokens)\n",
    "print(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d985faa0-e7a0-45a3-a7ff-034d188bc7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artificial', 'intelligence', 'ai', 'reshaping', 'world', 'ways', 'never', 'imagined', 'smart', 'assistants', 'like', 'alexa', 'autonomous', 'vehicles', 'ai', 'becoming', 'part', 'everyday', 'life', 'rise', 'machine', 'learning', 'algorithms', 'made', 'possible', 'predict', 'outcomes', 'jawdropping', 'accuracy', 'companies', 'like', 'openai', 'deepmind', 'pushing', 'boundaries', 'whats', 'possible', 'large', 'language', 'models', 'youre', 'curious', 'ai', 'projects', 'check', 'wwwfutureofaiorg', 'mindblowing', 'innovations', 'researchers', 'often', 'share', 'insights', 'via', 'email', 'like', 'airesearchfuturemailcom', 'collaborate', 'exchange', 'ideas', 'ai', 'even', 'entered', 'healthcare', 'assisting', 'doctors', 'diagnosing', 'diseases', 'faster', 'accurately', 'however', 'concerns', 'job', 'automation', 'data', 'privacy', 'ethical', 'implications', 'ever', 'want', 'attend', 'ai', 'workshop', 'call', '91', '9876543210', '—', '’', 'happening', 'worldwide', 'despite', 'challenges', 'one', 'thing', 'certain', 'ai', '’', 'future', '—', '’', 'already']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in word_tokens if word not in stop_words]\n",
    "print(filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b733c373-6020-4271-a769-45c8b3d4d607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequency Distribution (excluding stopwords):\n",
      "[('ai', 6), ('like', 3), ('’', 3), ('possible', 2), ('—', 2), ('artificial', 1), ('intelligence', 1), ('reshaping', 1), ('world', 1), ('ways', 1), ('never', 1), ('imagined', 1), ('smart', 1), ('assistants', 1), ('alexa', 1), ('autonomous', 1), ('vehicles', 1), ('becoming', 1), ('part', 1), ('everyday', 1), ('life', 1), ('rise', 1), ('machine', 1), ('learning', 1), ('algorithms', 1), ('made', 1), ('predict', 1), ('outcomes', 1), ('jawdropping', 1), ('accuracy', 1), ('companies', 1), ('openai', 1), ('deepmind', 1), ('pushing', 1), ('boundaries', 1), ('whats', 1), ('large', 1), ('language', 1), ('models', 1), ('youre', 1), ('curious', 1), ('projects', 1), ('check', 1), ('wwwfutureofaiorg', 1), ('mindblowing', 1), ('innovations', 1), ('researchers', 1), ('often', 1), ('share', 1), ('insights', 1), ('via', 1), ('email', 1), ('airesearchfuturemailcom', 1), ('collaborate', 1), ('exchange', 1), ('ideas', 1), ('even', 1), ('entered', 1), ('healthcare', 1), ('assisting', 1), ('doctors', 1), ('diagnosing', 1), ('diseases', 1), ('faster', 1), ('accurately', 1), ('however', 1), ('concerns', 1), ('job', 1), ('automation', 1), ('data', 1), ('privacy', 1), ('ethical', 1), ('implications', 1), ('ever', 1), ('want', 1), ('attend', 1), ('workshop', 1), ('call', 1), ('91', 1), ('9876543210', 1), ('happening', 1), ('worldwide', 1), ('despite', 1), ('challenges', 1), ('one', 1), ('thing', 1), ('certain', 1), ('future', 1), ('already', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "freq_dist = nltk.FreqDist(filtered_words)\n",
    "\n",
    "print(\"Word Frequency Distribution (excluding stopwords):\")\n",
    "print(freq_dist.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34501c4d-4670-4df5-8bb2-efda6f67e67f",
   "metadata": {},
   "source": [
    "# Q2: Stemming and Lemmatization\n",
    "1. Take the tokenized words from QuesƟon 1 (after stopword removal).\n",
    "2. Apply stemming using NLTK's PorterStemmer and LancasterStemmer.\n",
    "3. Apply lemmatization using NLTK's WordNetLemmatizer.\n",
    "4. Compare and display results of both techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "890ce354-c49d-43a6-ae52-0a3a77bf17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75266afb-2324-4c27-9800-f3c7d56187a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmed = [porter.stem(word) for word in filtered_words]\n",
    "lancaster_stemmed = [lancaster.stem(word) for word in filtered_words]\n",
    "lemmatized = [lemmatizer.lemmatize(word) for word in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb6b9983-8874-4568-bae5-a8402a041070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Porter Stemmer: ['artifici', 'intellig', 'ai', 'reshap', 'world', 'way', 'never', 'imagin', 'smart', 'assist', 'like', 'alexa', 'autonom', 'vehicl', 'ai', 'becom', 'part', 'everyday', 'life', 'rise', 'machin', 'learn', 'algorithm', 'made', 'possibl', 'predict', 'outcom', 'jawdrop', 'accuraci', 'compani', 'like', 'openai', 'deepmind', 'push', 'boundari', 'what', 'possibl', 'larg', 'languag', 'model', 'your', 'curiou', 'ai', 'project', 'check', 'wwwfutureofaiorg', 'mindblow', 'innov', 'research', 'often', 'share', 'insight', 'via', 'email', 'like', 'airesearchfuturemailcom', 'collabor', 'exchang', 'idea', 'ai', 'even', 'enter', 'healthcar', 'assist', 'doctor', 'diagnos', 'diseas', 'faster', 'accur', 'howev', 'concern', 'job', 'autom', 'data', 'privaci', 'ethic', 'implic', 'ever', 'want', 'attend', 'ai', 'workshop', 'call', '91', '9876543210', '—', '’', 'happen', 'worldwid', 'despit', 'challeng', 'one', 'thing', 'certain', 'ai', '’', 'futur', '—', '’', 'alreadi']\n",
      "\n",
      "Lancaster Stemmer: ['art', 'intellig', 'ai', 'reshap', 'world', 'way', 'nev', 'imagin', 'smart', 'assist', 'lik', 'alex', 'autonom', 'vehic', 'ai', 'becom', 'part', 'everyday', 'lif', 'ris', 'machin', 'learn', 'algorithm', 'mad', 'poss', 'predict', 'outcom', 'jawdrop', 'acc', 'company', 'lik', 'opena', 'deepmind', 'push', 'bound', 'what', 'poss', 'larg', 'langu', 'model', 'yo', 'cury', 'ai', 'project', 'check', 'wwwfutureofaiorg', 'mindblow', 'innov', 'research', 'oft', 'shar', 'insight', 'via', 'email', 'lik', 'airesearchfuturemailcom', 'collab', 'exchang', 'idea', 'ai', 'ev', 'ent', 'healthc', 'assist', 'doct', 'diagnos', 'diseas', 'fast', 'acc', 'howev', 'concern', 'job', 'autom', 'dat', 'priv', 'eth', 'imply', 'ev', 'want', 'attend', 'ai', 'workshop', 'cal', '91', '9876543210', '—', '’', 'hap', 'worldwid', 'despit', 'challeng', 'on', 'thing', 'certain', 'ai', '’', 'fut', '—', '’', 'already']\n",
      "\n",
      "Lemmatized: ['artificial', 'intelligence', 'ai', 'reshaping', 'world', 'way', 'never', 'imagined', 'smart', 'assistant', 'like', 'alexa', 'autonomous', 'vehicle', 'ai', 'becoming', 'part', 'everyday', 'life', 'rise', 'machine', 'learning', 'algorithm', 'made', 'possible', 'predict', 'outcome', 'jawdropping', 'accuracy', 'company', 'like', 'openai', 'deepmind', 'pushing', 'boundary', 'whats', 'possible', 'large', 'language', 'model', 'youre', 'curious', 'ai', 'project', 'check', 'wwwfutureofaiorg', 'mindblowing', 'innovation', 'researcher', 'often', 'share', 'insight', 'via', 'email', 'like', 'airesearchfuturemailcom', 'collaborate', 'exchange', 'idea', 'ai', 'even', 'entered', 'healthcare', 'assisting', 'doctor', 'diagnosing', 'disease', 'faster', 'accurately', 'however', 'concern', 'job', 'automation', 'data', 'privacy', 'ethical', 'implication', 'ever', 'want', 'attend', 'ai', 'workshop', 'call', '91', '9876543210', '—', '’', 'happening', 'worldwide', 'despite', 'challenge', 'one', 'thing', 'certain', 'ai', '’', 'future', '—', '’', 'already']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPorter Stemmer:\", porter_stemmed)\n",
    "print(\"\\nLancaster Stemmer:\", lancaster_stemmed)\n",
    "print(\"\\nLemmatized:\", lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f70a4-0fac-48a8-b31c-4766a45867fa",
   "metadata": {},
   "source": [
    "# Q3. Regular Expressions and Text Splitting\n",
    "1. Take the original text from Question 1.\n",
    "\n",
    "2. Use regular expressions to:\n",
    "\n",
    "a. Extract all words with more than 5 letters.\n",
    "\n",
    "b. Extract all numbers (if any exist in their text).\n",
    "\n",
    "c. Extract all capitalized words.\n",
    "\n",
    "3. Use text splitting techniques to:\n",
    "    \n",
    "a. Split the text into words containing only alphabets (removing digits and special characters).\n",
    "    \n",
    "b. Extract words starting with a vowel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b0392dd-63f1-41f2-a174-aa2f64ea4c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_gt_5 = re.findall(r'\\b\\w{6,}\\b', text)\n",
    "numbers = re.findall(r'\\d+', text)\n",
    "capitalized = re.findall(r'\\b[A-Z][a-z]*\\b', text)\n",
    "alpha_words = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "vowel_words = [word for word in alpha_words if word[0].lower() in 'aeiou']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06a285e5-9396-4d81-b479-02e4a9f833bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Words > 5 letters: ['Artificial', 'Intelligence', 'reshaping', 'imagined', 'assistants', 'autonomous', 'vehicles', 'becoming', 'everyday', 'machine', 'learning', 'algorithms', 'possible', 'predict', 'outcomes', 'dropping', 'accuracy', 'Companies', 'OpenAI', 'DeepMind', 'pushing', 'boundaries', 'possible', 'language', 'models', 'curious', 'projects', 'futureofai', 'blowing', 'innovations', 'Researchers', 'insights', 'research', 'futuremail', 'collaborate', 'exchange', 'entered', 'healthcare', 'assisting', 'doctors', 'diagnosing', 'diseases', 'faster', 'accurately', 'However', 'concerns', 'automation', 'privacy', 'ethical', 'implications', 'attend', 'workshop', '9876543210', 'happening', 'worldwide', 'Despite', 'challenges', 'certain', 'future', 'already']\n",
      "\n",
      "Numbers: ['91', '9876543210']\n",
      "\n",
      "Capitalized Words: ['Artificial', 'Intelligence', 'From', 'Alexa', 'The', 'Companies', 'If', 'Researchers', 'However', 'If', 'Despite']\n",
      "\n",
      "Alphabetic Words: ['Artificial', 'Intelligence', 'AI', 'is', 'reshaping', 'the', 'world', 'in', 'ways', 'we', 'never', 'imagined', 'From', 'smart', 'assistants', 'like', 'Alexa', 'to', 'autonomous', 'vehicles', 'AI', 'is', 'becoming', 'part', 'of', 'everyday', 'life', 'The', 'rise', 'of', 'machine', 'learning', 'algorithms', 'has', 'made', 'it', 'possible', 'to', 'predict', 'outcomes', 'with', 'jaw', 'dropping', 'accuracy', 'Companies', 'like', 'OpenAI', 'and', 'DeepMind', 'are', 'pushing', 'the', 'boundaries', 'of', 'what', 's', 'possible', 'with', 'large', 'language', 'models', 'If', 'you', 're', 'curious', 'about', 'AI', 'projects', 'check', 'out', 'www', 'futureofai', 'org', 'for', 'some', 'mind', 'blowing', 'innovations', 'Researchers', 'often', 'share', 'insights', 'via', 'email', 'like', 'at', 'ai', 'research', 'futuremail', 'com', 'to', 'collaborate', 'and', 'exchange', 'ideas', 'AI', 'has', 'even', 'entered', 'healthcare', 'assisting', 'doctors', 'in', 'diagnosing', 'diseases', 'faster', 'and', 'more', 'accurately', 'However', 'there', 'are', 'concerns', 'about', 'job', 'automation', 'data', 'privacy', 'and', 'ethical', 'implications', 'If', 'you', 'ever', 'want', 'to', 'attend', 'an', 'AI', 'workshop', 'call', 'they', 're', 'happening', 'worldwide', 'Despite', 'the', 'challenges', 'one', 'thing', 'is', 'certain', 'AI', 'isn', 't', 'just', 'the', 'future', 'it', 's', 'already', 'here']\n",
      "\n",
      "Words starting with vowels: ['Artificial', 'Intelligence', 'AI', 'is', 'in', 'imagined', 'assistants', 'Alexa', 'autonomous', 'AI', 'is', 'of', 'everyday', 'of', 'algorithms', 'it', 'outcomes', 'accuracy', 'OpenAI', 'and', 'are', 'of', 'If', 'about', 'AI', 'out', 'org', 'innovations', 'often', 'insights', 'email', 'at', 'ai', 'and', 'exchange', 'ideas', 'AI', 'even', 'entered', 'assisting', 'in', 'and', 'accurately', 'are', 'about', 'automation', 'and', 'ethical', 'implications', 'If', 'ever', 'attend', 'an', 'AI', 'one', 'is', 'AI', 'isn', 'it', 'already']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nWords > 5 letters:\", words_gt_5)\n",
    "print(\"\\nNumbers:\", numbers)\n",
    "print(\"\\nCapitalized Words:\", capitalized)\n",
    "print(\"\\nAlphabetic Words:\", alpha_words)\n",
    "print(\"\\nWords starting with vowels:\", vowel_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032f08d-892b-4e7d-9334-f53033936dca",
   "metadata": {},
   "source": [
    "# Q4. Custom Tokenization & Regex-based Text Cleaning\n",
    "1. Take original text from Question 1.\n",
    "\n",
    "2. Write a custom tokenization function that:\n",
    "a. Removes punctuation and special symbols, but keeps contractions (e.g., \"isn't\" should not be split into \"is\" and \"n't\").\n",
    "\n",
    "b. Handles hyphenated words as a single token (e.g., \"state-of-the-art\" remains a single token).\n",
    "\n",
    "c. Tokenizes numbers separately but keeps decimal numbers intact (e.g., \"3.14\" should remain as is).\n",
    "\n",
    "3. Use Regex Substitutions (re.sub) to:\n",
    "\n",
    "a. Replace email addresses with '' placeholder.\n",
    "\n",
    "b. Replace URLs with '' placeholder.\n",
    "\n",
    "c. Replace phone numbers (formats: 123-456-7890 or +91 9876543210) with '' placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be401367-ff42-48ff-a6f1-f9d814104f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Tokens: ['Artificial', 'Intelligence', 'AI', 'is', 'reshaping', 'the', 'world', 'in', 'ways', 'we', 'never', 'imagined', 'From', 'smart', 'assistants', 'like', 'Alexa', 'to', 'autonomous', 'vehicles', 'AI', 'is', 'becoming', 'part', 'of', 'everyday', 'life', 'The', 'rise', 'of', 'machine', 'learning', 'algorithms', 'has', 'made', 'it', 'possible', 'to', 'predict', 'outcomes', 'with', 'jaw-dropping', 'accuracy', 'Companies', 'like', 'OpenAI', 'and', 'DeepMind', 'are', 'pushing', 'the', 'boundaries', 'of', \"what's\", 'possible', 'with', 'large', 'language', 'models', 'If', \"you're\", 'curious', 'about', 'AI', 'projects', 'check', 'out', 'www', 'futureofai', 'org', 'for', 'some', 'mind-blowing', 'innovations', 'Researchers', 'often', 'share', 'insights', 'via', 'email', 'like', 'at', 'ai', 'research', 'futuremail', 'com', 'to', 'collaborate', 'and', 'exchange', 'ideas', 'AI', 'has', 'even', 'entered', 'healthcare', 'assisting', 'doctors', 'in', 'diagnosing', 'diseases', 'faster', 'and', 'more', 'accurately', 'However', 'there', 'are', 'concerns', 'about', 'job', 'automation', 'data', 'privacy', 'and', 'ethical', 'implications', 'If', 'you', 'ever', 'want', 'to', 'attend', 'an', 'AI', 'workshop', 'call', '91', '9876543210', 'they', 're', 'happening', 'worldwide', 'Despite', 'the', 'challenges', 'one', 'thing', 'is', 'certain', 'AI', 'isn', 't', 'just', 'the', 'future', 'it', 's', 'already', 'here']\n",
      "\n",
      "Text after substitutions: \n",
      "Artificial Intelligence (AI) is reshaping the world in ways we never imagined. From smart assistants like Alexa to autonomous vehicles, AI is becoming part of everyday life. The rise of machine learning algorithms has made it possible to predict outcomes with jaw-dropping accuracy. Companies like OpenAI and DeepMind are pushing the boundaries of what's possible with large language models. If you're curious about AI projects, check out <URL> for some mind-blowing innovations. Researchers often share insights via email, like at <EMAIL>, to collaborate and exchange ideas. AI has even entered healthcare, assisting doctors in diagnosing diseases faster and more accurately. However, there are concerns about job automation, data privacy, and ethical implications. If you ever want to attend an AI workshop, call +91 <PHONE> — they’re happening worldwide. Despite the challenges, one thing is certain: AI isn’t just the future — it’s already here.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def custom_tokenizer(text):\n",
    "    pattern = r\"\\b(?:[a-zA-Z]+(?:'[a-z]+)?(?:-[a-z]+)*|\\d+(?:\\.\\d+)?)\\b\"\n",
    "    return re.findall(pattern, text)\n",
    "\n",
    "custom_tokens = custom_tokenizer(text)\n",
    "\n",
    "text_sub = re.sub(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b', '<EMAIL>', text)\n",
    "text_sub = re.sub(r'http\\S+|www\\.\\S+', '<URL>', text_sub)\n",
    "text_sub = re.sub(r'\\b(?:\\+91[-\\s]?|0)?\\d{10}\\b|\\d{3}-\\d{3}-\\d{4}', '<PHONE>', text_sub)\n",
    "\n",
    "print(\"\\nCustom Tokens:\", custom_tokens)\n",
    "print(\"\\nText after substitutions:\", text_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d0e549-4d8d-4019-87ae-3bcdd28e26f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
